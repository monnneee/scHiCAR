## This pipeline was used for generating pseudo-bulk fastq files by extracting DNA reads from the same clusters or cell types that identidied by scHiCAR RNA library.

To run this pipeline, you need to install the following software:
- **seqtk**: [install](https://github.com/lh3/seqtk)
- **pigz**: [install](https://zlib.net/pigz/)
- **nextflow**: [install](https://www.nextflow.io/docs/latest/install.html)
  
#### 1. Extract DNA barcodes for each sample
```bash

# bash code

for i in {1..40}  #all samples 
  
do

# The input files sample${i}.barcode.cut_rank are from the 'filtered-genome' output folder in the 2_DNA directory generated by Snakemake.

cut -d' ' -f2 sample${i}.barcode.cut_rank|sort -k1b,1|join -j 1 - DNA-RNA_barcode.dict|awk '{print"sample'$i'_"$2"\tsample'$i'_"$1}' OFS='\t' > sample${i}_RNA_DNA.barcode # the 1st column is RNA barcode and 2nd column is matched DNA barcode  
  
done  
  
cat sample*_RNA_DNA.barcode > total_RNA_DNA_barcode.txt # merge the total samples together that are used in the 'dna_barcode.R' script  

```
#### 2. Add DNA barcodes to the Seurat object generated from RNA library
```r

# R code

library(Seurat)

rna_seurat_object<-readRDS("rna_seurat.rds") # read personalized analysis results by Seurat based on filtered matrix from 1_RNA directory

dna_barcode<-read.table("total_RNA_DNA_barcode.txt",sep='\t',header=F,row.names=1) #1st column is RNA barcode and 2nd column is DNA barcode

dna_bd<-dna_barcode$V2

names(dna_bd)<-rownames(dna_barcode)

rna_seurat_object$temp<-names(rna_seurat_object$orig.ident)

rna_filtered_object<-subset(rna_seurat_object,temp %in% rownames(dna_barcode)) #filter out cells without matched DNA barcodes

rna_filtered_object$temp<-NULL

rna_filtered_object <- AddMetaData(object = rna_filtered_object, metadata = dna_bd,col.name = 'dna_barcode')

```

#### 3. Extract DNA barcodes after identified clusters or annotated cell types
```r

# R code

cluster<-names(table(rna_filtered_object$cluster)) #get total cluster name

cluster_list<-as.list(cluster)

for (i in 1:length(cluster)){

mkdir cluster_list[[i]]

bd<-subset(rna_filtered_object,cluster %in% cluster_list[[i]])$dna_barcode

names(bd)<-NULL

write.table(bd,paste(cluster_list[[i]],"/total_dna_barcode",sep=""),sep="\t",quote=FALSE,col.names=FALSE,row.names=FALSE)

} #each cluster has an output file named "total_dna_barcode" that includes mixed samples

```


#### 4. Export DNA barcodes from the same cluster or cell type for each sample
```bash  

# bash code

for i in {1..22} # all clusters
  
do
  
perl -p -e "s/_/\t/g" cluster${i}/total_dna_barcode > cluster${i}/temp && mv cluster${i}/temp cluster${i}/total_dna_barcode # split DNA barcode lines: 1st column is sampleID and 2nd column is DNA barcodes; "total_dna_barcode" files were generated by "dna_barcode.R"
  
for j in {1..40}  # all samples  
  
do
  
awk '{if($1=="sample'$j'"){print$2}}' cluster${i}/total_dna_barcode > cluster${i}/sample${j}_barcode.txt  
  
done  
  
done #outputs DNA barcodes for each samples in each cluster  
```
  
#### 5. Extract DNA reads based on barcodes for each samples in each cluster or cell type
```bash

# bash code

mkdir final_readName  
  
for m in {1..40} # all samples  
  
do
  
zcat DNA_fastq/sample${m}_R1.fastq.gz | awk -F " " '{if(NR%4==1){print $1}}' > sample${m}_DNA_readName # extract all read names from read1 fastq file 

for n in {1..22} # all clusters  
  
do
  
python3 match.py -l sample${m}_DNA_readName -s cluster${n}/sample${m}_barcode.txt -o final_readName/cluster${n}_sample${m}_readName  
  
done  
  
done  
```
  
#### 6. Generate fastq file for each cluster or cell type
```bash

# bash code

for i in {1..22} # all clusters  
  
do
  
for j in {1..40}  # all samples  
  
do
  
seqtk subseq DNA_fastq/sample${i}_R1.fastq.gz final_readName/cluster${i}_sample${j}_readName >> cluster${i}_R1.fastq  
  
seqtk subseq DNA_fastq/sample${i}_R2.fastq.gz final_readName/cluster${i}_sample${j}_readName >> cluster${i}_R2.fastq  
  
done  
  
pigz -p 8 cluster${i}_R1.fastq  
  
pigz -p 8 cluster${i}_R2.fastq  
  
done  
```
  
#### 7. The output file (cluster${i}_R*.fastq.gz) as pseudo-bulk fastq files were used for running [nf-core/hicar](https://github.com/jianhong/hicar/tree/dev2rc)
```bash

# bash code

nextflow pull jianhong/hicar -r dev2rc #dev2rc is the newest version  
  
nextflow run jianhong/hicar -profile singularity --genome mm10 -r dev2rc --input samplesheet.csv --skip_fastqc --skip_cutadapt --outdir result --skip_interactions --skip_tads --skip_diff_analysis --skip_peak_qc --skip_igv --skip_trackhub --skip_circos --pairtools_parse_version parse2 -resume
```  
The scripts used in <mark>scHiCAR paper</mark> refer to the nf-core/hicar pipeline, the details can be found in [paper_scripts.md](https://github.com/monnneee/scHiCAR/blob/main/3_create_pseudo-bulk_fastq/paper_scripts.md)
